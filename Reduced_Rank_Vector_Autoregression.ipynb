{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reduced-Rank Vector Autoregression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjaYFC0kJ9fs"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jL92XpzKkUI"
      },
      "source": [
        "Since the closed-form solution to W involves V, and the closed-form solution to V involves W, we can use an Alternating Minimization scheme. For the least squares solutions, the algorithm is actually Alternating Least Squares (ALS). There are only three main steps of this iterative algorithm:\n",
        "\n",
        "\n",
        "\n",
        "*   Initialize W and V with random values.\n",
        "*   Iterative step 1: Update W by the least squares solution as mentioned above.\n",
        "*   Iterative step 2: Update V by the least squares solution as mentioned above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoGU7180KaKb"
      },
      "source": [
        "def rrvar(data, R, pred_step, maxiter = 100):\n",
        "    \"\"\"\n",
        "    Reduced-rank VAR algorithm.\n",
        "    R is the desired reduced rank.\n",
        "    \"\"\"\n",
        "    \n",
        "    N, T = data.shape\n",
        "    X1 = data[:, : -1]\n",
        "    X2 = data[:, 1 :]\n",
        "    V = np.random.randn(R, N)\n",
        "    for it in range(maxiter):\n",
        "        W = X2 @ np.linalg.pinv(V @ X1)\n",
        "        V = np.linalg.pinv(W) @ X2 @ np.linalg.pinv(X1)\n",
        "    mat = np.append(data, np.zeros((N, pred_step)), axis = 1)\n",
        "    for s in range(pred_step):\n",
        "        mat[:, T + s] = W @ V @ mat[:, T + s - 1]\n",
        "    return mat[:, - pred_step :]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIK1CjGhK7eA"
      },
      "source": [
        "Example Data: X is an array of observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvvudGCoK8-5",
        "outputId": "ca1080d9-5117-4948-885c-17c96026e290"
      },
      "source": [
        "X = np.zeros((20, 10))\n",
        "for i in range(20):\n",
        "    X[i, :] = np.arange(i + 1, i + 11)\n",
        "\n",
        "print(X)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
            " [ 2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
            " [ 3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]\n",
            " [ 4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]\n",
            " [ 5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n",
            " [ 6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n",
            " [ 7.  8.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
            " [ 8.  9. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
            " [ 9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
            " [10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
            " [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
            " [12. 13. 14. 15. 16. 17. 18. 19. 20. 21.]\n",
            " [13. 14. 15. 16. 17. 18. 19. 20. 21. 22.]\n",
            " [14. 15. 16. 17. 18. 19. 20. 21. 22. 23.]\n",
            " [15. 16. 17. 18. 19. 20. 21. 22. 23. 24.]\n",
            " [16. 17. 18. 19. 20. 21. 22. 23. 24. 25.]\n",
            " [17. 18. 19. 20. 21. 22. 23. 24. 25. 26.]\n",
            " [18. 19. 20. 21. 22. 23. 24. 25. 26. 27.]\n",
            " [19. 20. 21. 22. 23. 24. 25. 26. 27. 28.]\n",
            " [20. 21. 22. 23. 24. 25. 26. 27. 28. 29.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoKegiolQwEo"
      },
      "source": [
        "The goal is to use the defined rrvar function to forecast x11 and x12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV6FnA_3PSZ0",
        "outputId": "f6853889-b90b-4c5d-b312-be200b7c5751"
      },
      "source": [
        "pred_step = 2\n",
        "R = 2\n",
        "mat_hat = rrvar(X, R, pred_step)\n",
        "print(mat_hat)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11. 12.]\n",
            " [12. 13.]\n",
            " [13. 14.]\n",
            " [14. 15.]\n",
            " [15. 16.]\n",
            " [16. 17.]\n",
            " [17. 18.]\n",
            " [18. 19.]\n",
            " [19. 20.]\n",
            " [20. 21.]\n",
            " [21. 22.]\n",
            " [22. 23.]\n",
            " [23. 24.]\n",
            " [24. 25.]\n",
            " [25. 26.]\n",
            " [26. 27.]\n",
            " [27. 28.]\n",
            " [28. 29.]\n",
            " [29. 30.]\n",
            " [30. 31.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obPI8vBGPcm7"
      },
      "source": [
        "As you can see, the results are the same as the ground truth data. "
      ]
    }
  ]
}